{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dealing with class imbalance:\n",
    "- resampling techniques\n",
    "    - under or over sampling random vs informed\n",
    "    - SMOTE synthetic minor ...\n",
    "- kappa statistics/ MCC Metric\n",
    "- multiclass mcc \"comparing two k-category assignments by a k-category correlation coeeficient\"\n",
    "\n",
    "\n",
    "spatial pyramid pooling in deep convolutional networks for visual recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers\n",
    "from pathlib import Path\n",
    "import keras\n",
    "import random\n",
    "from keras.utils import Sequence\n",
    "import skimage\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "from skimage.util import pad\n",
    "from skimage.util import crop\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MY_Gen(Sequence):\n",
    "\n",
    "    def __init__(self, image_filenames, labels, batch_size, shuffle):\n",
    "        self.image_filenames, self.labels = image_filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "        self.num_labels = len(np.unique(labels))\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.image_filenames) / float(self.batch_size)))\n",
    "    \n",
    "    def crop_or_pad(self, image, dim):\n",
    "        x, y, _ = image.shape\n",
    "        if y < dim and x < dim:\n",
    "            image = pad(image, ((math.ceil((dim - image.shape[0])/2),math.floor((dim - image.shape[0])/2)),\n",
    "                                (math.ceil((dim - image.shape[1])/2),math.floor((dim - image.shape[1])/2)), \n",
    "                                (0,0)), 'constant', constant_values = 255)\n",
    "        elif y > dim and x > dim:\n",
    "            rand1 = random.randint(1,x-dim)\n",
    "            rand2 = random.randint(1,y-dim)\n",
    "            image = crop(image, ((rand1,x-dim-rand1),(rand2,y-dim-rand2),(0,0)))\n",
    "        elif x > dim:\n",
    "            rand1 = random.randint(1,x-dim)\n",
    "            image = pad(image, ((0,0),\n",
    "                                (math.ceil((dim - y)/2),math.floor((dim - y)/2)), \n",
    "                                (0,0)), 'constant', constant_values = 255)\n",
    "            image = crop(image, ((rand1,x-dim-rand1),\n",
    "                                (0,0), (0,0)))\n",
    "        else:\n",
    "            rand2 = random.randint(1,y-dim)\n",
    "            image = pad(image, ((math.ceil((dim - x)/2),math.floor((dim - x)/2)),\n",
    "                                (0,0), \n",
    "                                (0,0)), 'constant', constant_values = 255)\n",
    "            image = crop(image, ((0,0),\n",
    "                                 (rand2,y-dim-rand2), (0,0)))\n",
    "        return image\n",
    "    \n",
    "    def read_im(self, filename, dim):\n",
    "        image = imread(filename)\n",
    "        #image = resize(image, (dim,dim), anti_aliasing = True, mode = \"reflect\")\n",
    "        image = skimage.color.gray2rgb(image)\n",
    "        image = self.crop_or_pad(image, dim)\n",
    "        return image\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.image_filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        image = [self.read_im(filename, 299) for filename in batch_x]\n",
    "        image = (image-np.amin(image))/(np.amax(image)-np.amin(image))\n",
    "        #batch_y = keras.utils.to_categorical(batch_y, self.num_labels)\n",
    "        return np.array(image), np.array(batch_y)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle == True:\n",
    "            fnames_and_labels = list(zip(self.image_filenames, self.labels))\n",
    "            random.shuffle(fnames_and_labels)\n",
    "            self.image_filenames, self.labels = zip(*fnames_and_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "path = './data/test/'\n",
    "def fetch_data_set(path, ftype = 'jpg'):\n",
    "    p = Path(path)\n",
    "    files = list(p.glob('**/*.'+ftype))\n",
    "    classes = str(files).split('/')\n",
    "    classes = [classes[i] for i in list(range(2,len(classes),3)) ]\n",
    "    classnames, indices = np.unique(classes, return_inverse=True)\n",
    "    dict_classes = dict(zip(classnames, list(range(0,len(classes)))))\n",
    "    return files, classes, dict_classes\n",
    "\n",
    "#np.array([dict_[i] for i in classes])\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from itertools import chain\n",
    "\n",
    "def over_under_sample(files, classes, dict_classes, num_to_undersample = 15000, num_to_oversample = 7500):\n",
    "    files_array = np.array(files).reshape(-1,1)\n",
    "    dic = {}\n",
    "    for i in list(classes):\n",
    "        dic[i] = dic.get(i,0) + 1\n",
    "\n",
    "    classes_to_oversample = dict((k, v) for k, v in dic.items() if v < num_to_oversample)\n",
    "    classes_to_undersample = dict((k, v) for k, v in dic.items() if v > num_to_undersample)    \n",
    "    \n",
    "    for key, value in classes_to_undersample.items():\n",
    "        classes_to_undersample[key] = num_to_undersample\n",
    "    for key, value in classes_to_oversample.items():\n",
    "        classes_to_oversample[key] = num_to_oversample\n",
    "    \n",
    "    ros = RandomOverSampler(sampling_strategy = classes_to_oversample)\n",
    "    rus = RandomUnderSampler(sampling_strategy = classes_to_undersample)\n",
    "    x_over, y_over = ros.fit_resample(files_array, classes)\n",
    "    x_under, y_under = rus.fit_resample(x_over, y_over)\n",
    "    x_under = list(chain(*x_under.tolist()))\n",
    "    return x_under, y_under\n",
    "    \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data_train_validation_test(data_X, data_Y, test_percent, validation_percent, seed): \n",
    "    assert (test_percent < 1) and (0 < validation_percent) and (validation_percent < 1)\n",
    "    X_tmp, X_val, Y_tmp, Y_val = train_test_split(data_X, data_Y, test_size=validation_percent, shuffle=True, random_state=seed)\n",
    "    \n",
    "    if test_percent != 0:\n",
    "        relative_test_percent = test_percent / (1 - validation_percent)\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X_tmp, Y_tmp, test_size=relative_test_percent, shuffle=True, random_state=seed)\n",
    "        split_data = [X_train, Y_train, X_val, Y_val, X_test, Y_test]\n",
    "    else:\n",
    "        X_train, Y_train = X_tmp, Y_tmp\n",
    "        split_data = [X_train, Y_train, X_val, Y_val]\n",
    "\n",
    "    return split_data  \n",
    "\n",
    "def encode_labels(labels, OneHot=True, encoder = None):\n",
    "    if OneHot and encoder == None:\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "        enc = OneHotEncoder()\n",
    "        enc.fit(np.array(labels).reshape(-1, 1))\n",
    "        OneHot = enc.transform(np.array(labels).reshape(-1, 1)).toarray()\n",
    "        return OneHot, enc\n",
    "    else:\n",
    "        OneHot = encoder.transform(np.array(labels).reshape(-1, 1)).toarray()\n",
    "        return OneHot\n",
    "    # mlb \n",
    "    #1 convert labels to multilabel using hardcoded dict\n",
    "    #2 fit mlb\n",
    "    #3 transform \n",
    "    # return labels and encoder\n",
    "    # repeat for when encoder is present\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florianmuthreich/.local/lib/python3.5/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (150) in class dolio will be larger than the number of samples in the majority class (class #dolio -> 72)\n",
      "  n_samples_majority))\n",
      "/home/florianmuthreich/.local/lib/python3.5/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (150) in class onca will be larger than the number of samples in the majority class (class #dolio -> 72)\n",
      "  n_samples_majority))\n",
      "/home/florianmuthreich/.local/lib/python3.5/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (150) in class cavo will be larger than the number of samples in the majority class (class #dolio -> 72)\n",
      "  n_samples_majority))\n"
     ]
    }
   ],
   "source": [
    "# read dataset\n",
    "files, classes, dict_classes = fetch_data_set(\"./data/test/\")\n",
    "# split dataset\n",
    "split = split_data_train_validation_test(files, classes, 0.05, .25, random.randint(1,10000))\n",
    "split[0], split[1] = over_under_sample(split[0], split[1], dict_classes, num_to_oversample = 150)\n",
    "# load label encoder and transform labels\n",
    "split[1], OH_enc = encode_labels(split[1], OneHot = True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#from collections import Counter\n",
    "#print(sorted(Counter(classes).items()))\n",
    "#print(sorted(Counter(y_re).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Annelida': 0,\n",
       " 'Bivalvia__Mollusca': 1,\n",
       " 'Brachyura': 2,\n",
       " 'Candaciidae': 3,\n",
       " 'Cavoliniidae': 4,\n",
       " 'Centropagidae': 5,\n",
       " 'Corycaeidae': 6,\n",
       " 'Coscinodiscus': 7,\n",
       " 'Decapoda': 8,\n",
       " 'Doliolida': 9,\n",
       " 'Eucalanidae': 10,\n",
       " 'Euchaetidae': 11,\n",
       " 'Evadne': 12,\n",
       " 'Foraminifera': 13,\n",
       " 'Fritillariidae': 14,\n",
       " 'Haloptilus': 15,\n",
       " 'Harpacticoida': 16,\n",
       " 'Limacinidae': 17,\n",
       " 'Noctiluca': 18,\n",
       " 'Oikopleuridae': 19,\n",
       " 'Oncaeidae': 20,\n",
       " 'Ostracoda': 21,\n",
       " 'Penilia': 22,\n",
       " 'Phaeodaria': 23,\n",
       " 'Salpida': 24,\n",
       " 'Temoridae': 25,\n",
       " 'calyptopsis': 26,\n",
       " 'cyphonaute': 27,\n",
       " 'egg__Actinopterygii': 28,\n",
       " 'egg__other': 29,\n",
       " 'eudoxie__Diphyidae': 30,\n",
       " 'gonophore__Diphyidae': 31,\n",
       " 'multiple__Copepoda': 32,\n",
       " 'multiple__other': 33,\n",
       " 'nauplii__Cirripedia': 34,\n",
       " 'nauplii__Crustacea': 35,\n",
       " 'nectophore__Diphyidae': 36,\n",
       " 'tail__Appendicularia': 37,\n",
       " 'tail__Chaetognatha': 38,\n",
       " 'zoea__Decapoda': 39}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#c,_= np.unique(split[5], return_inverse=True)\n",
    "#len(c)\n",
    "#b = {}\n",
    "#for i in list(split[5]):\n",
    "#    b[i] = b.get(i,0) + 1\n",
    "\n",
    "#counts = dict((k, v) for k, v in b.items() if v > 1)\n",
    "#counts\n",
    "\n",
    "#f, c, d = fetch_data_set('./data/imgs')\n",
    "#d['cavo'] = [0,1,1]\n",
    "#[d[i] for i in c]\n",
    "d_ = d\n",
    "d_['Annelida'] = ['Annelida', 'Metazoa', 'Eukaryota']\n",
    "d_['Bivalvia__Molusca'] = ['Bivalvia__Molusca', 'Mollusca', 'Metazoa', 'Eukaryota']\n",
    "d_['Brachyura'] = ['Brachyura', 'Decapoda', 'Malacostraca', 'Arthropoda', 'Metazoa', 'Eukaryota']\n",
    "d_['Candaciidae'] = ['Candaciidae', 'Calanoida', 'Copepoda', 'Maxillopoda', 'Arthropoda', 'Metazoa', 'Eukaryota']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('./data/test/') \n",
    "files = list(p.glob('**/*.jpg'))\n",
    "classes = str(files).split('/')\n",
    "classes = [classes[i] for i in list(range(2,len(classes),3)) ]\n",
    "classnames, indices = np.unique(classes, return_inverse=True)\n",
    "labels = keras.utils.to_categorical(indices, len(np.unique(indices)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('./data/imgs/') \n",
    "files = list(p.glob('**/*.jpg'))\n",
    "classes = str(files).split('/')\n",
    "classes = [classes[i] for i in list(range(2,len(classes),3)) ]\n",
    "classnames, indices = np.unique(classes, return_inverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22500"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(split[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values([15000, 15000, 15000, 15000])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(list(counts.values()))\n",
    "counts\n",
    "classes_to_oversample = dict((k, v) for k, v in b.items() if v < 7500)\n",
    "classes_to_undersample = dict((k, v) for k, v in b.items() if v > 15000)\n",
    "#assign new target values for sampling\n",
    "for key, value in classes_to_undersample.items():\n",
    "    classes_to_undersample[key] = 15000\n",
    "classes_to_undersample.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_data_train_validation_test(data_X, data_Y, test_percent, validation_percent, seed): \n",
    "    assert (test_percent < 1) and (0 < validation_percent) and (validation_percent < 1)\n",
    "    X_tmp, X_val, Y_tmp, Y_val = train_test_split(data_X, data_Y, test_size=validation_percent, shuffle=True, random_state=seed)\n",
    "    \n",
    "    if test_percent != 0:\n",
    "        relative_test_percent = test_percent / (1 - validation_percent)\n",
    "        X_train, X_test, Y_train, Y_test = train_test_split(X_tmp, Y_tmp, test_size=relative_test_percent, shuffle=True, random_state=seed)\n",
    "        split_data = [X_train, Y_train, X_val, Y_val, X_test, Y_test]\n",
    "    else:\n",
    "        X_train, Y_train = X_tmp, Y_tmp\n",
    "        split_data = [X_train, Y_train, X_val, Y_val]\n",
    "\n",
    "    return split_data\n",
    "\n",
    "split = split_data_train_validation_test(files, classes, 0, .25, 1190)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 75), (1, 78), (2, 72)]\n",
      "[(0, 150), (1, 300), (2, 72)]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/florianmuthreich/.local/lib/python3.5/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (150) in class 0 will be larger than the number of samples in the majority class (class #1 -> 78)\n",
      "  n_samples_majority))\n",
      "/home/florianmuthreich/.local/lib/python3.5/site-packages/imblearn/utils/_validation.py:257: UserWarning: After over-sampling, the number of samples (300) in class 1 will be larger than the number of samples in the majority class (class #1 -> 78)\n",
      "  n_samples_majority))\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "d = {0: 150, 1: 300}\n",
    "ros = RandomOverSampler(random_state = 0, sampling_strategy = d)\n",
    "x_re, y_re = ros.fit_resample(np.array(split[0]).reshape(-1,1), split[1])\n",
    "from collections import Counter\n",
    "print(sorted(Counter(split[1]).items()))\n",
    "print(sorted(Counter(y_re).items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 2, 2, 2, 0, 0, 0, 1, 2, 0,\n",
       "       1, 0, 1, 1, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 2, 0, 2, 2, 1, 0, 2,\n",
       "       1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 2, 1, 1, 1, 2, 2, 2, 0, 2, 1, 1, 1,\n",
       "       2, 0, 0, 0, 0, 1, 2, 0, 2, 1, 1, 2, 2, 1, 0, 2, 2, 1, 2, 0, 1, 0,\n",
       "       0, 2, 1, 2, 1, 1, 0, 1, 2, 1, 2, 0, 0, 1, 2, 0, 0, 2, 2, 1, 0, 1,\n",
       "       0, 2, 2, 2, 0, 2, 1, 1, 2, 2, 2, 2, 0, 0, 1, 0, 2, 2, 1, 2, 0, 1,\n",
       "       1, 2, 2, 0, 0, 1, 0, 2, 1, 2, 1, 2, 0, 1, 2, 2, 1, 2, 0, 0, 0, 0,\n",
       "       2, 0, 2, 1, 2, 0, 0, 2, 0, 0, 2, 0, 0, 1, 1, 1, 2, 2, 0, 1, 1, 1,\n",
       "       1, 2, 1, 1, 2, 0, 1, 0, 1, 1, 1, 2, 0, 2, 0, 1, 2, 1, 1, 1, 0, 1,\n",
       "       1, 2, 1, 0, 1, 2, 2, 0, 2, 0, 2, 1, 1, 2, 0, 0, 1, 2, 0, 0, 1, 2,\n",
       "       2, 1, 1, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from itertools import chain\n",
    "\n",
    "x_re = list(chain(*x_re.tolist()))\n",
    "y_re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'numpy.ndarray'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-a512a4a96f52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_re\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mv\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'numpy.ndarray'"
     ]
    }
   ],
   "source": [
    "#import keras_metrics\n",
    "#metrics=[keras_metrics.precision(), keras_metrics.recall()\n",
    "b = {}\n",
    "for i in list(np.array(x_re)):\n",
    "    b[i] = b.get(i,0) + 1\n",
    "\n",
    "dict((k, v) for k, v in b.items() if v > 1)\n",
    "\n",
    "#x_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "import keras_metrics\n",
    "from keras import backend as K\n",
    "\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=30\n",
    "#num_training_samples=len(files)\n",
    "\n",
    "files, classes, dict_classes =  fetch_data_set('./data/test')\n",
    "split = split_data_train_validation_test(files, classes, .1, .25, 666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'get_key'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-d662273c92b1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#len(np.argmax(model_pred, axis = 1, out = None)), len(test_pred), len(split[5])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#[dict_classes[i] for i in split[5]], list(test_pred)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mdict_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'get_key'"
     ]
    }
   ],
   "source": [
    "pd.crosstab(np.array([dict_classes[i] for i in split[5]]), (test_pred), rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "#len(split[5]), len(test_pred)\n",
    "#len(np.argmax(model_pred, axis = 1, out = None)), len(test_pred), len(split[5])\n",
    "#[dict_classes[i] for i in split[5]], list(test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "arrays and names must have the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-43ecb337adba>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#test_actu = np.argmax([dict_classes[i] for i in split[5]], axis = 1, out = None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrownames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Actual'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolnames\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Predicted'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmargins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36mcrosstab\u001b[0;34m(index, columns, values, rownames, colnames, aggfunc, margins, margins_name, dropna, normalize)\u001b[0m\n\u001b[1;32m    463\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_make_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 465\u001b[0;31m     \u001b[0mrownames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrownames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'row'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    466\u001b[0m     \u001b[0mcolnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_names\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'col'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    467\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pandas/core/reshape/pivot.py\u001b[0m in \u001b[0;36m_get_names\u001b[0;34m(arrs, names, prefix)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 585\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAssertionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'arrays and names must have the same length'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    586\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m             \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: arrays and names must have the same length"
     ]
    }
   ],
   "source": [
    "#[dict_classes[i] for i in split[1]]\n",
    "import pandas as pd\n",
    "model_pred = model.predict_generator(generator = test_batch, steps = (len(split[4]) // batch_size))\n",
    "#test_actu = np.argmax([dict_classes[i] for i in split[5]], axis = 1, out = None)\n",
    "test_pred = np.argmax(model_pred, axis = 1, out = None)\n",
    "pd.crosstab(split[5], test_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "15/15 [==============================] - 4s 247ms/step - loss: 1.0279 - precision: 0.6165 - recall: 0.5467 - acc: 0.6689\n",
      "Epoch 2/5\n",
      "15/15 [==============================] - 3s 183ms/step - loss: 0.2488 - precision: 0.8718 - recall: 0.9067 - acc: 0.9111\n",
      "Epoch 3/5\n",
      "15/15 [==============================] - 3s 180ms/step - loss: 0.1092 - precision: 0.9662 - recall: 0.9533 - acc: 0.9667\n",
      "Epoch 4/5\n",
      "15/15 [==============================] - 3s 177ms/step - loss: 0.0596 - precision: 0.9671 - recall: 0.9800 - acc: 0.9822\n",
      "Epoch 5/5\n",
      "15/15 [==============================] - 3s 177ms/step - loss: 0.0876 - precision: 0.9533 - recall: 0.9533 - acc: 0.9689\n"
     ]
    }
   ],
   "source": [
    "batch_size = 30\n",
    "training_batch = MY_Gen(split[0], split[1], batch_size, shuffle = True)\n",
    "#validation_batch = MY_Gen(split[2], [dict_classes[i] for i in split[3]], batch_size, shuffle = True)#files, indices\n",
    "#test_batch = MY_Gen(split[4], [dict_classes[i] for i in split[5]], batch_size, shuffle = False)\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[keras_metrics.precision(), keras_metrics.recall(),'accuracy'])\n",
    "\n",
    "history = model.fit_generator(generator=training_batch,\n",
    "                    #validation_data = validation_batch,\n",
    "                    #validation_steps = (len(split[2]) // batch_size),\n",
    "                    steps_per_epoch=(len(split[0]) // batch_size),\n",
    "                    epochs=5,\n",
    "                    verbose=1,\n",
    "                    use_multiprocessing=False,\n",
    "                    workers=16,\n",
    "                    max_queue_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cavo</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dolio</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>onca</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0   1  2  All\n",
       "Actual                  \n",
       "cavo       4   1  0    5\n",
       "dolio      0   6  0    6\n",
       "onca       0   3  1    4\n",
       "All        4  10  1   15"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#split[5] = encode_labels(split[5], OneHot=True, encoder = OH_enc)\n",
    "test_batch = MY_Gen(split[4], split[5], 15, shuffle = False)\n",
    "model_pred = model.predict_generator(generator = test_batch, steps = (len(split[4]) // 15))\n",
    "t = {v: k for k, v in dict_classes.items()}\n",
    "test_actu = OH_enc.inverse_transform(split[5]).flatten()\n",
    "test_pred = t[i] for i in np.argmax(model_pred, axis = 1, out = None)\n",
    "pd.crosstab(test_actu, test_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your classifier probably misclassifies some images. Investigate how well the accuracy of the\n",
    "classifications match the softmax output values, for instance as a histogram with softmax\n",
    "intervals (buckets) on the x-axis (e.g. 0.70-0.75), and the percentage correct classifications for\n",
    "each bucket (e.g. 68%) on the y-axis. Is your classifier overconfident or underconfident, or\n",
    "neutral?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([0. , 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1. ])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#plt.hist(acc)\n",
    "#plt.show()\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(np.arange(0,10,1), height = acc.flatten())\n",
    "plt.xticks(np.arange(0,10,1), ['0-0.1','0.1-0.2','0.2-0.3','0.3-0.4','0.4-0.5','0.5-0.6','0.6-0.7','0.7-0.8','0.8-0.9','0.9-1'])\n",
    "plt.xlabel(\"Softmax Intervals\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Sofmax calibration\")\n",
    "plt.show()\n",
    "plt.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        ],\n",
       "       [0.        ],\n",
       "       [0.        ],\n",
       "       [0.5       ],\n",
       "       [0.66666667],\n",
       "       [0.8       ],\n",
       "       [0.55555556],\n",
       "       [0.58333333],\n",
       "       [0.61538462],\n",
       "       [0.6       ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "bins = np.arange(0,1.1,0.1)\n",
    "rng = np.random.RandomState(10)\n",
    "acc = np.zeros([10,1])\n",
    "pred = np.array(rng.normal(.5,.25,size=15)).reshape(5,3)\n",
    "actu = np.repeat(np.array([False,True,False,True,True]), 3)\n",
    "for i in range(len(bins)-1):\n",
    "    tmp = ((pred < bins[i]).flatten() & (pred < bins[i+1]).flatten())\n",
    "    if sum(tmp) == 0:\n",
    "        acc[i] = 0\n",
    "    else:\n",
    "        acc[i] = sum(tmp * actu)/sum(tmp)\n",
    "\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.hist(pred.flatten(), range = (0,1))\n",
    "plt.xlabel(\"Softmax Intervals\")\n",
    "plt.ylabel(\"No of Samples\")\n",
    "plt.title(\"Sofmax calibration\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "with open(\"data/output/models/pretra_INC.json\", \"w\") as json_file:\n",
    "    json_file.write(json_string)\n",
    "\n",
    "model.save_weights(\"data/output/models/pretra_INC_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#im=np.asarray(Image.open(files[1]).resize([299,299]))\n",
    "#im = im/np.amax(im)\n",
    "#import matplotlib.pyplot as plt\n",
    "#plt.imshow(image[7])\n",
    "#plt.show()\n",
    "#ind = np.arange(105)\n",
    "#isinstance(classes, list)\n",
    "#len(classes)\n",
    "import random\n",
    "c=list(zip(files,classes))\n",
    "random.shuffle(c)\n",
    "files,classes = zip (*c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "im = resize(imread(files[1]), (100, 100))\n",
    "im = skimage.color.gray2rgb(im)\n",
    "im.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#im = np.array([(Image.open(file_name).resize([299,299])) for file_name in files])\n",
    "#im2 = np.array([\n",
    "           # resize(imread(file_name), (299, 299))\n",
    "            #   for file_name in files])\n",
    "#len(im2)\n",
    "#im2.shape\n",
    "#im.shape\n",
    "def norm_im(filename, dim):\n",
    "    image = imread(filename)\n",
    "    image = resize(image, (dim,dim), mode = \"edge\")\n",
    "    image = (image-np.amin(image))/(np.amax(image)-np.amin(image))\n",
    "    return image\n",
    "image = np.array([norm_im(filename, 100) for filename in files])\n",
    "\n",
    "\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#files[range(1,10)]\n",
    "list(indices)\n",
    "keras.utils.to_categorical(indices, 5)\n",
    "len(np.unique(indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(3, activation='softmax')(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "# model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=100\n",
    "num_training_samples=len(files)\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "my_training_batch_generator = MY_Gen(files, labels, batch_size)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "# train the model on the new data for a few epochs\n",
    "model.fit_generator(generator=my_training_batch_generator,\n",
    "                                          steps_per_epoch=(num_training_samples // batch_size),\n",
    "                                          epochs=10,\n",
    "                                          verbose=1,\n",
    "                                          use_multiprocessing=False,\n",
    "                                          workers=16,\n",
    "                                          max_queue_size=32,\n",
    "                             shuffle = True)\n",
    "\n",
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 249 layers and unfreeze the rest:\n",
    "for layer in model.layers[:249]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[249:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss='categorical_crossentropy')\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "model.fit_generator(...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "p = Path('./data/imgs/') \n",
    "classes = [x for x in p.iterdir() if x.is_dir()]\n",
    "files = list(p.glob('**/*.jpg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 1, 0, 0, 1, 0, 0]]),\n",
       " [('blue', 'dress', 'no_legs'), ('black', 'blue', 'dress', 'no_legs')])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "labels = [\n",
    "    (\"legs\",\"blue\", \"jeans\"),\n",
    "    (\"no_legs\",\"blue\", \"dress\"),\n",
    "    (\"no_legs\",\"red\", \"dress\"),\n",
    "    (\"no_legs\",\"red\", \"shirt\"),\n",
    "    (\"no_legs\",\"blue\", \"shirt\"),\n",
    "    (\"no_legs\",\"black\", \"jeans\")]\n",
    "mlb = MultiLabelBinarizer()\n",
    "mlb.fit(labels)\n",
    "\n",
    "mlb.classes_\n",
    "\n",
    "mlb.transform([(\"blue\", \"dress\", \"no_legs\")]), mlb.inverse_transform(np.array([[0, 1, 1, 0, 0, 1, 0, 0], [1, 1, 1, 0, 0, 1, 0, 0]]))\n",
    "#np.array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 1., 0.],\n",
       "       [1., 0., 0.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(np.array(split[5]).reshape(-1, 1))\n",
    "OneHot=enc.transform(np.array(split[5]).reshape(-1, 1)).toarray()\n",
    "#enc.inverse_transform(OneHot)\n",
    "OneHot[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PosixPath('data/test/cavo/992612.jpg'),\n",
       " PosixPath('data/test/cavo/1158831.jpg'),\n",
       " PosixPath('data/test/cavo/993180.jpg'),\n",
       " PosixPath('data/test/cavo/996279.jpg'),\n",
       " PosixPath('data/test/cavo/12747088.jpg'),\n",
       " PosixPath('data/test/cavo/1158620.jpg'),\n",
       " PosixPath('data/test/cavo/992773.jpg'),\n",
       " PosixPath('data/test/cavo/994128.jpg'),\n",
       " PosixPath('data/test/cavo/1158767.jpg'),\n",
       " PosixPath('data/test/cavo/996858.jpg'),\n",
       " PosixPath('data/test/cavo/993866.jpg'),\n",
       " PosixPath('data/test/cavo/993300.jpg'),\n",
       " PosixPath('data/test/cavo/12746529.jpg'),\n",
       " PosixPath('data/test/cavo/12746695.jpg'),\n",
       " PosixPath('data/test/cavo/12746864.jpg'),\n",
       " PosixPath('data/test/cavo/1158573.jpg'),\n",
       " PosixPath('data/test/cavo/12747169.jpg'),\n",
       " PosixPath('data/test/cavo/994685.jpg'),\n",
       " PosixPath('data/test/cavo/993520.jpg'),\n",
       " PosixPath('data/test/cavo/995387.jpg'),\n",
       " PosixPath('data/test/cavo/993928.jpg'),\n",
       " PosixPath('data/test/cavo/1158518.jpg'),\n",
       " PosixPath('data/test/cavo/12747201.jpg'),\n",
       " PosixPath('data/test/cavo/993824.jpg'),\n",
       " PosixPath('data/test/cavo/993086.jpg'),\n",
       " PosixPath('data/test/cavo/993810.jpg'),\n",
       " PosixPath('data/test/cavo/1158416.jpg'),\n",
       " PosixPath('data/test/cavo/996606.jpg'),\n",
       " PosixPath('data/test/cavo/1158833.jpg'),\n",
       " PosixPath('data/test/cavo/994174.jpg'),\n",
       " PosixPath('data/test/cavo/996043.jpg'),\n",
       " PosixPath('data/test/cavo/997003.jpg'),\n",
       " PosixPath('data/test/cavo/1158743.jpg'),\n",
       " PosixPath('data/test/cavo/993310.jpg'),\n",
       " PosixPath('data/test/cavo/996305.jpg'),\n",
       " PosixPath('data/test/cavo/993787.jpg'),\n",
       " PosixPath('data/test/cavo/12746885.jpg'),\n",
       " PosixPath('data/test/cavo/12746723.jpg'),\n",
       " PosixPath('data/test/cavo/12746481.jpg'),\n",
       " PosixPath('data/test/cavo/12747367.jpg'),\n",
       " PosixPath('data/test/cavo/994140.jpg'),\n",
       " PosixPath('data/test/cavo/1158435.jpg'),\n",
       " PosixPath('data/test/cavo/1158890.jpg'),\n",
       " PosixPath('data/test/cavo/12747278.jpg'),\n",
       " PosixPath('data/test/cavo/1158907.jpg'),\n",
       " PosixPath('data/test/cavo/993779.jpg'),\n",
       " PosixPath('data/test/cavo/992955.jpg'),\n",
       " PosixPath('data/test/cavo/1158812.jpg'),\n",
       " PosixPath('data/test/cavo/1158452.jpg'),\n",
       " PosixPath('data/test/cavo/993754.jpg'),\n",
       " PosixPath('data/test/cavo/992971.jpg'),\n",
       " PosixPath('data/test/cavo/12747060.jpg'),\n",
       " PosixPath('data/test/cavo/1158630.jpg'),\n",
       " PosixPath('data/test/cavo/12747368.jpg'),\n",
       " PosixPath('data/test/cavo/995652.jpg'),\n",
       " PosixPath('data/test/cavo/993901.jpg'),\n",
       " PosixPath('data/test/cavo/996171.jpg'),\n",
       " PosixPath('data/test/cavo/1158794.jpg'),\n",
       " PosixPath('data/test/cavo/993476.jpg'),\n",
       " PosixPath('data/test/cavo/1158499.jpg'),\n",
       " PosixPath('data/test/cavo/996018.jpg'),\n",
       " PosixPath('data/test/cavo/1158757.jpg'),\n",
       " PosixPath('data/test/cavo/12746601.jpg'),\n",
       " PosixPath('data/test/cavo/994009.jpg'),\n",
       " PosixPath('data/test/cavo/1158874.jpg'),\n",
       " PosixPath('data/test/cavo/1158749.jpg'),\n",
       " PosixPath('data/test/cavo/12747093.jpg'),\n",
       " PosixPath('data/test/cavo/993382.jpg'),\n",
       " PosixPath('data/test/cavo/997017.jpg'),\n",
       " PosixPath('data/test/cavo/995195.jpg'),\n",
       " PosixPath('data/test/cavo/12746590.jpg'),\n",
       " PosixPath('data/test/cavo/12746587.jpg'),\n",
       " PosixPath('data/test/cavo/12747115.jpg'),\n",
       " PosixPath('data/test/cavo/993154.jpg'),\n",
       " PosixPath('data/test/cavo/1158758.jpg'),\n",
       " PosixPath('data/test/cavo/12747178.jpg'),\n",
       " PosixPath('data/test/cavo/12747129.jpg'),\n",
       " PosixPath('data/test/cavo/1158772.jpg'),\n",
       " PosixPath('data/test/cavo/993024.jpg'),\n",
       " PosixPath('data/test/cavo/1158820.jpg'),\n",
       " PosixPath('data/test/cavo/1158902.jpg'),\n",
       " PosixPath('data/test/cavo/12747015.jpg'),\n",
       " PosixPath('data/test/cavo/995316.jpg'),\n",
       " PosixPath('data/test/cavo/12746470.jpg'),\n",
       " PosixPath('data/test/cavo/994040.jpg'),\n",
       " PosixPath('data/test/cavo/1158864.jpg'),\n",
       " PosixPath('data/test/cavo/992977.jpg'),\n",
       " PosixPath('data/test/cavo/1158796.jpg'),\n",
       " PosixPath('data/test/cavo/994704.jpg'),\n",
       " PosixPath('data/test/cavo/12747085.jpg'),\n",
       " PosixPath('data/test/cavo/996295.jpg'),\n",
       " PosixPath('data/test/cavo/995331.jpg'),\n",
       " PosixPath('data/test/cavo/992678.jpg'),\n",
       " PosixPath('data/test/cavo/1158771.jpg'),\n",
       " PosixPath('data/test/cavo/993261.jpg'),\n",
       " PosixPath('data/test/cavo/12746966.jpg'),\n",
       " PosixPath('data/test/cavo/12747274.jpg'),\n",
       " PosixPath('data/test/cavo/1158761.jpg'),\n",
       " PosixPath('data/test/cavo/992719.jpg'),\n",
       " PosixPath('data/test/cavo/1158478.jpg'),\n",
       " PosixPath('data/test/dolio/14435641.jpg'),\n",
       " PosixPath('data/test/dolio/14435612.jpg'),\n",
       " PosixPath('data/test/dolio/14435653.jpg'),\n",
       " PosixPath('data/test/dolio/14435695.jpg'),\n",
       " PosixPath('data/test/dolio/14435631.jpg'),\n",
       " PosixPath('data/test/dolio/14435640.jpg'),\n",
       " PosixPath('data/test/dolio/14435602.jpg'),\n",
       " PosixPath('data/test/dolio/14435637.jpg'),\n",
       " PosixPath('data/test/dolio/14435633.jpg'),\n",
       " PosixPath('data/test/dolio/14435659.jpg'),\n",
       " PosixPath('data/test/dolio/14435597.jpg'),\n",
       " PosixPath('data/test/dolio/14435608.jpg'),\n",
       " PosixPath('data/test/dolio/14435643.jpg'),\n",
       " PosixPath('data/test/dolio/14435660.jpg'),\n",
       " PosixPath('data/test/dolio/14435598.jpg'),\n",
       " PosixPath('data/test/dolio/13626049.jpg'),\n",
       " PosixPath('data/test/dolio/14435618.jpg'),\n",
       " PosixPath('data/test/dolio/14435615.jpg'),\n",
       " PosixPath('data/test/dolio/14435625.jpg'),\n",
       " PosixPath('data/test/dolio/14435688.jpg'),\n",
       " PosixPath('data/test/dolio/14435642.jpg'),\n",
       " PosixPath('data/test/dolio/14435667.jpg'),\n",
       " PosixPath('data/test/dolio/14435614.jpg'),\n",
       " PosixPath('data/test/dolio/14435644.jpg'),\n",
       " PosixPath('data/test/dolio/14435627.jpg'),\n",
       " PosixPath('data/test/dolio/14435679.jpg'),\n",
       " PosixPath('data/test/dolio/14435691.jpg'),\n",
       " PosixPath('data/test/dolio/14435621.jpg'),\n",
       " PosixPath('data/test/dolio/14435666.jpg'),\n",
       " PosixPath('data/test/dolio/14435622.jpg'),\n",
       " PosixPath('data/test/dolio/14435676.jpg'),\n",
       " PosixPath('data/test/dolio/14435658.jpg'),\n",
       " PosixPath('data/test/dolio/14435684.jpg'),\n",
       " PosixPath('data/test/dolio/14435664.jpg'),\n",
       " PosixPath('data/test/dolio/14435624.jpg'),\n",
       " PosixPath('data/test/dolio/14435654.jpg'),\n",
       " PosixPath('data/test/dolio/14435682.jpg'),\n",
       " PosixPath('data/test/dolio/14435689.jpg'),\n",
       " PosixPath('data/test/dolio/14435648.jpg'),\n",
       " PosixPath('data/test/dolio/992756.jpg'),\n",
       " PosixPath('data/test/dolio/14435681.jpg'),\n",
       " PosixPath('data/test/dolio/14435674.jpg'),\n",
       " PosixPath('data/test/dolio/14435687.jpg'),\n",
       " PosixPath('data/test/dolio/14435634.jpg'),\n",
       " PosixPath('data/test/dolio/14435606.jpg'),\n",
       " PosixPath('data/test/dolio/14435609.jpg'),\n",
       " PosixPath('data/test/dolio/14435675.jpg'),\n",
       " PosixPath('data/test/dolio/14435603.jpg'),\n",
       " PosixPath('data/test/dolio/14435617.jpg'),\n",
       " PosixPath('data/test/dolio/14435610.jpg'),\n",
       " PosixPath('data/test/dolio/14435629.jpg'),\n",
       " PosixPath('data/test/dolio/14435694.jpg'),\n",
       " PosixPath('data/test/dolio/14435662.jpg'),\n",
       " PosixPath('data/test/dolio/14435632.jpg'),\n",
       " PosixPath('data/test/dolio/14435596.jpg'),\n",
       " PosixPath('data/test/dolio/14435663.jpg'),\n",
       " PosixPath('data/test/dolio/14435626.jpg'),\n",
       " PosixPath('data/test/dolio/14435630.jpg'),\n",
       " PosixPath('data/test/dolio/14435670.jpg'),\n",
       " PosixPath('data/test/dolio/14435692.jpg'),\n",
       " PosixPath('data/test/dolio/14435600.jpg'),\n",
       " PosixPath('data/test/dolio/14435657.jpg'),\n",
       " PosixPath('data/test/dolio/14435690.jpg'),\n",
       " PosixPath('data/test/dolio/14435683.jpg'),\n",
       " PosixPath('data/test/dolio/995737.jpg'),\n",
       " PosixPath('data/test/dolio/14435680.jpg'),\n",
       " PosixPath('data/test/dolio/14435619.jpg'),\n",
       " PosixPath('data/test/dolio/14435651.jpg'),\n",
       " PosixPath('data/test/dolio/14435628.jpg'),\n",
       " PosixPath('data/test/dolio/14435616.jpg'),\n",
       " PosixPath('data/test/dolio/14435605.jpg'),\n",
       " PosixPath('data/test/dolio/14435636.jpg'),\n",
       " PosixPath('data/test/dolio/14435604.jpg'),\n",
       " PosixPath('data/test/dolio/14435678.jpg'),\n",
       " PosixPath('data/test/dolio/14435652.jpg'),\n",
       " PosixPath('data/test/dolio/14435685.jpg'),\n",
       " PosixPath('data/test/dolio/14435668.jpg'),\n",
       " PosixPath('data/test/dolio/14435601.jpg'),\n",
       " PosixPath('data/test/dolio/14435635.jpg'),\n",
       " PosixPath('data/test/dolio/14435669.jpg'),\n",
       " PosixPath('data/test/dolio/14435661.jpg'),\n",
       " PosixPath('data/test/dolio/14435611.jpg'),\n",
       " PosixPath('data/test/dolio/14435655.jpg'),\n",
       " PosixPath('data/test/dolio/14435647.jpg'),\n",
       " PosixPath('data/test/dolio/14435650.jpg'),\n",
       " PosixPath('data/test/dolio/14435677.jpg'),\n",
       " PosixPath('data/test/dolio/14435649.jpg'),\n",
       " PosixPath('data/test/dolio/14435607.jpg'),\n",
       " PosixPath('data/test/dolio/14435613.jpg'),\n",
       " PosixPath('data/test/dolio/14435646.jpg'),\n",
       " PosixPath('data/test/dolio/14435638.jpg'),\n",
       " PosixPath('data/test/dolio/14435673.jpg'),\n",
       " PosixPath('data/test/dolio/14435623.jpg'),\n",
       " PosixPath('data/test/dolio/14435665.jpg'),\n",
       " PosixPath('data/test/dolio/14435656.jpg'),\n",
       " PosixPath('data/test/dolio/14435671.jpg'),\n",
       " PosixPath('data/test/dolio/14435599.jpg'),\n",
       " PosixPath('data/test/dolio/14435645.jpg'),\n",
       " PosixPath('data/test/dolio/14435620.jpg'),\n",
       " PosixPath('data/test/dolio/14435672.jpg'),\n",
       " PosixPath('data/test/onca/14431807.jpg'),\n",
       " PosixPath('data/test/onca/14431775.jpg'),\n",
       " PosixPath('data/test/onca/14431751.jpg'),\n",
       " PosixPath('data/test/onca/14431826.jpg'),\n",
       " PosixPath('data/test/onca/14431812.jpg'),\n",
       " PosixPath('data/test/onca/14431821.jpg'),\n",
       " PosixPath('data/test/onca/14431771.jpg'),\n",
       " PosixPath('data/test/onca/994458.jpg'),\n",
       " PosixPath('data/test/onca/14431748.jpg'),\n",
       " PosixPath('data/test/onca/14431758.jpg'),\n",
       " PosixPath('data/test/onca/14431825.jpg'),\n",
       " PosixPath('data/test/onca/14431844.jpg'),\n",
       " PosixPath('data/test/onca/14431769.jpg'),\n",
       " PosixPath('data/test/onca/14431833.jpg'),\n",
       " PosixPath('data/test/onca/14431810.jpg'),\n",
       " PosixPath('data/test/onca/14431832.jpg'),\n",
       " PosixPath('data/test/onca/14431827.jpg'),\n",
       " PosixPath('data/test/onca/14431746.jpg'),\n",
       " PosixPath('data/test/onca/14431779.jpg'),\n",
       " PosixPath('data/test/onca/14431813.jpg'),\n",
       " PosixPath('data/test/onca/14431803.jpg'),\n",
       " PosixPath('data/test/onca/14431800.jpg'),\n",
       " PosixPath('data/test/onca/14431787.jpg'),\n",
       " PosixPath('data/test/onca/14431781.jpg'),\n",
       " PosixPath('data/test/onca/14431754.jpg'),\n",
       " PosixPath('data/test/onca/14431792.jpg'),\n",
       " PosixPath('data/test/onca/14431799.jpg'),\n",
       " PosixPath('data/test/onca/14431809.jpg'),\n",
       " PosixPath('data/test/onca/14431829.jpg'),\n",
       " PosixPath('data/test/onca/14431822.jpg'),\n",
       " PosixPath('data/test/onca/14431804.jpg'),\n",
       " PosixPath('data/test/onca/14431761.jpg'),\n",
       " PosixPath('data/test/onca/14431798.jpg'),\n",
       " PosixPath('data/test/onca/14431806.jpg'),\n",
       " PosixPath('data/test/onca/14431841.jpg'),\n",
       " PosixPath('data/test/onca/14431797.jpg'),\n",
       " PosixPath('data/test/onca/14431786.jpg'),\n",
       " PosixPath('data/test/onca/14431745.jpg'),\n",
       " PosixPath('data/test/onca/14431815.jpg'),\n",
       " PosixPath('data/test/onca/14431764.jpg'),\n",
       " PosixPath('data/test/onca/14431784.jpg'),\n",
       " PosixPath('data/test/onca/14431796.jpg'),\n",
       " PosixPath('data/test/onca/14431824.jpg'),\n",
       " PosixPath('data/test/onca/14431743.jpg'),\n",
       " PosixPath('data/test/onca/14431757.jpg'),\n",
       " PosixPath('data/test/onca/14431836.jpg'),\n",
       " PosixPath('data/test/onca/14431837.jpg'),\n",
       " PosixPath('data/test/onca/14431817.jpg'),\n",
       " PosixPath('data/test/onca/14431768.jpg'),\n",
       " PosixPath('data/test/onca/14431814.jpg'),\n",
       " PosixPath('data/test/onca/14431835.jpg'),\n",
       " PosixPath('data/test/onca/14431839.jpg'),\n",
       " PosixPath('data/test/onca/14431816.jpg'),\n",
       " PosixPath('data/test/onca/14431762.jpg'),\n",
       " PosixPath('data/test/onca/14431766.jpg'),\n",
       " PosixPath('data/test/onca/14431749.jpg'),\n",
       " PosixPath('data/test/onca/14431770.jpg'),\n",
       " PosixPath('data/test/onca/14431783.jpg'),\n",
       " PosixPath('data/test/onca/14431760.jpg'),\n",
       " PosixPath('data/test/onca/14431819.jpg'),\n",
       " PosixPath('data/test/onca/14431840.jpg'),\n",
       " PosixPath('data/test/onca/14431767.jpg'),\n",
       " PosixPath('data/test/onca/14431753.jpg'),\n",
       " PosixPath('data/test/onca/14431759.jpg'),\n",
       " PosixPath('data/test/onca/14431777.jpg'),\n",
       " PosixPath('data/test/onca/14431802.jpg'),\n",
       " PosixPath('data/test/onca/14431801.jpg'),\n",
       " PosixPath('data/test/onca/14431778.jpg'),\n",
       " PosixPath('data/test/onca/14431788.jpg'),\n",
       " PosixPath('data/test/onca/14431793.jpg'),\n",
       " PosixPath('data/test/onca/14431774.jpg'),\n",
       " PosixPath('data/test/onca/14431752.jpg'),\n",
       " PosixPath('data/test/onca/14431780.jpg'),\n",
       " PosixPath('data/test/onca/14431756.jpg'),\n",
       " PosixPath('data/test/onca/14431765.jpg'),\n",
       " PosixPath('data/test/onca/14431747.jpg'),\n",
       " PosixPath('data/test/onca/14431830.jpg'),\n",
       " PosixPath('data/test/onca/14431842.jpg'),\n",
       " PosixPath('data/test/onca/14431791.jpg'),\n",
       " PosixPath('data/test/onca/14431794.jpg'),\n",
       " PosixPath('data/test/onca/14431763.jpg'),\n",
       " PosixPath('data/test/onca/14431782.jpg'),\n",
       " PosixPath('data/test/onca/14431818.jpg'),\n",
       " PosixPath('data/test/onca/14431811.jpg'),\n",
       " PosixPath('data/test/onca/14431773.jpg'),\n",
       " PosixPath('data/test/onca/14431772.jpg'),\n",
       " PosixPath('data/test/onca/14431820.jpg'),\n",
       " PosixPath('data/test/onca/14431785.jpg'),\n",
       " PosixPath('data/test/onca/995314.jpg'),\n",
       " PosixPath('data/test/onca/14431750.jpg'),\n",
       " PosixPath('data/test/onca/14431808.jpg'),\n",
       " PosixPath('data/test/onca/14431828.jpg'),\n",
       " PosixPath('data/test/onca/14431744.jpg'),\n",
       " PosixPath('data/test/onca/14431823.jpg'),\n",
       " PosixPath('data/test/onca/14431838.jpg'),\n",
       " PosixPath('data/test/onca/14431795.jpg'),\n",
       " PosixPath('data/test/onca/14431776.jpg'),\n",
       " PosixPath('data/test/onca/14431790.jpg'),\n",
       " PosixPath('data/test/onca/14431834.jpg'),\n",
       " PosixPath('data/test/onca/13107988.jpg')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = Path('./data/test')\n",
    "end = '.jpg'\n",
    "list(p.glob('**/*'+end))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
