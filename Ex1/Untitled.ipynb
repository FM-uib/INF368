{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import random as rn\n",
    "\n",
    "import os\n",
    "from skimage import io\n",
    "from skimage.transform import resize, rotate\n",
    "from skimage.util import pad\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical, plot_model\n",
    "\n",
    "import itertools\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Dropout\n",
    "from keras.layers import Dropout, Flatten, Dense, Input, Concatenate, Reshape, Flatten\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "# import tensorflow as tf\n",
    "\n",
    "import datetime\n",
    "import time\n",
    "import threading\n",
    "\n",
    "datafolder = os.getenv('data', 'data')\n",
    "outputfolder = os.path.join(datafolder, 'output')\n",
    "imgfolder = os.path.join(datafolder, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_and_save_model(name, model, train_gen,  \n",
    "                       steps_per_epoch = 10,  epochs=10, img_input=True):\n",
    "    \n",
    "    modeloutputfolder = os.path.join(outputfolder, name, datetime.datetime.now().strftime(\"%Y-%m-%d-%H-%M\"))\n",
    "    if not os.path.exists(modeloutputfolder):\n",
    "        os.makedirs(modeloutputfolder)\n",
    "    \n",
    "    cbs=[ModelCheckpoint(filepath=os.path.join(modeloutputfolder,'model_fitted.h5'), verbose=1, save_best_only=True),\n",
    "         CSVLogger(os.path.join(modeloutputfolder,'model_history.csv'), separator=',', append=False)]\n",
    "         \n",
    "    start_time = time.time()\n",
    "    history = model.fit_generator(train_gen,\n",
    "                             steps_per_epoch=steps_per_epoch,\n",
    "                             #validation_data=validation_gen,\n",
    "                             #validation_steps=validation_steps,\n",
    "                             epochs=epochs, \n",
    "                            callbacks=cbs)\n",
    "    end_time = time.time()\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code from:\n",
    "# https://github.com/keras-team/keras/issues/1638\n",
    "\n",
    "class threadsafe_iter:\n",
    "    \"\"\"Takes an iterator/generator and makes it thread-safe by\n",
    "    serializing call to the `next` method of given iterator/generator.\n",
    "    \"\"\"\n",
    "    def __init__(self, it):\n",
    "        self.it = it\n",
    "        self.lock = threading.Lock()\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self): # Py3\n",
    "        with self.lock:\n",
    "            return next(self.it)\n",
    "\n",
    "    def next(self):     # Py2\n",
    "        with self.lock:\n",
    "            return self.it.next()\n",
    "\n",
    "\n",
    "def threadsafe_generator(f):\n",
    "    \"\"\"A decorator that takes a generator function and makes it thread-safe.\n",
    "    \"\"\"\n",
    "    def g(*a, **kw):\n",
    "        return threadsafe_iter(f(*a, **kw))\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGenerators(object):\n",
    "    def __init__(self, path, val_fac=0.1, batch_size=16, validation_size=64, target_size=(224,224)):\n",
    "        self.path = path\n",
    "        self.val_fac = val_fac\n",
    "        self.batch_size = batch_size\n",
    "        self.validation_size = validation_size\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        self.labels = os.listdir(path)\n",
    "        self.number_labels = len(self.labels)\n",
    "        self.number_label_elements = {}\n",
    "        self.label_paths = {}\n",
    "        self.label_len = {}\n",
    "        self.images = {}\n",
    "        self.labels_to_classify = []\n",
    "        for i, l in enumerate(self.labels):\n",
    "            self.label_paths[i] = os.path.join(self.path, l)\n",
    "            self.images[i] = (os.listdir(self.label_paths[i]))\n",
    "            self.label_len[i] = len(self.images[i])\n",
    "        self.test_split = int(val_fac*min(self.label_len.values()))\n",
    "        self.val_split = int(2*val_fac*min(self.label_len.values()))\n",
    "        self.val_steps = int(self.number_labels*(self.val_split-self.test_split)/self.batch_size)\n",
    "        self.val_log = []\n",
    "        self.training_log = []\n",
    "    \n",
    "    def make_square(self, image, mode='constant'):\n",
    "        max_dim = max(image.shape)\n",
    "        pads = ((int((max_dim-image.shape[0])/2),\n",
    "                int((max_dim-image.shape[0])/2)),\n",
    "                (int((max_dim-image.shape[1])/2),\n",
    "                int((max_dim-image.shape[1])/2)))\n",
    "        if (mode=='constant'):\n",
    "            image = pad(image,pads , mode=mode, constant_values=255)\n",
    "        else:\n",
    "            image = pad(image,pads , mode=mode)\n",
    "        return resize(image, (224,224), mode=mode)\n",
    "\n",
    "    def augment_image(self, image):\n",
    "        if(np.random.choice([True, False])):\n",
    "            image = np.flip(image, axis=1)\n",
    "        max_dim = max(image.shape)\n",
    "        #pads = ((0, int((max_dim-image.shape[0]))),\n",
    "        #            (0, int((max_dim-image.shape[1])/2)))\n",
    "        #image = pad(image,pads , mode='constant', constant_values=255)\n",
    "        #angle = np.random.random_integers(0,359)\n",
    "        #resize_var = np.random.choice([True, False])\n",
    "        #image = rotate(image, angle, resize=True, mode=np.random.choice(['symmetric', 'reflect', 'wrap', 'edge']))\n",
    "        return self.make_square(image, mode='constant')\n",
    "\n",
    "    def get_statistics(self, image):\n",
    "        return (max(image.shape)/1024.0, min(image.shape)/1024.0, np.sum(image==255)/(1.0*np.product(image.shape)))\n",
    "\n",
    "    def base_generator(self, augment_image, get_random_label_and_image):\n",
    "        output_list = []\n",
    "        output_labels = []\n",
    "        while not len(output_list) == self.batch_size:\n",
    "            random_label, random_image = next(get_random_label_and_image)\n",
    "            output_labels.append(random_label)\n",
    "            output_list.append(os.path.join(self.label_paths[random_label], self.images[random_label][random_image]))\n",
    "        output_images = [io.imread(fp) for fp in output_list]\n",
    "        output_statistics = [self.get_statistics(image) for image in output_images]\n",
    "        output_augmented_images = [augment_image(image).reshape(224,224,1) for image in output_images]\n",
    "        return (np.stack(output_augmented_images),  \n",
    "              to_categorical(np.stack(output_labels), num_classes = self.number_labels))\n",
    "\n",
    "    def training_image_selector(self):\n",
    "        while True:\n",
    "            random_label = np.random.choice( self.number_labels)\n",
    "            random_image = np.random.choice(range(self.val_split, self.label_len[random_label]))\n",
    "            self.training_log.append((random_label, random_image))\n",
    "            yield (random_label, random_image)\n",
    "    \n",
    "    @threadsafe_generator\n",
    "    def training_generator(self):\n",
    "        it = self.training_image_selector()\n",
    "        while True:\n",
    "            yield self.base_generator(self.augment_image, it)\n",
    "\n",
    "    def val_image_selector(self):\n",
    "        while True:\n",
    "            for random_label in range(self.number_labels):\n",
    "                for random_image in range(self.test_split, self.val_split):\n",
    "                    self.val_log.append((random_label, random_image))\n",
    "                    yield (random_label, random_image)\n",
    "        \n",
    "    \n",
    "    @threadsafe_generator\n",
    "    def validation_generator(self):\n",
    "        it = self.val_image_selector()\n",
    "        while True:\n",
    "            yield self.base_generator(self.make_square, it)    \n",
    "    \n",
    "    def test_image_selector(self):\n",
    "        while True:\n",
    "            for random_label in range(self.number_labels):\n",
    "                for random_image in range(self.test_split):\n",
    "                    yield (random_label, random_image)\n",
    "    \n",
    "    @threadsafe_generator\n",
    "    def test_generator(self):\n",
    "        it = self.test_image_selector()\n",
    "        while True:\n",
    "            yield self.base_generator(self.make_square, it)    \n",
    "\n",
    "\n",
    "@threadsafe_generator            \n",
    "def make_image_generator(gen):\n",
    "    while True:\n",
    "        res = next(gen)\n",
    "        yield res[0][0], res[1]\n",
    "\n",
    "@threadsafe_generator\n",
    "def make_stat_generator(gen):\n",
    "    while True:\n",
    "        res = next(gen)\n",
    "        yield res[0][1], res[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dategen = MyGenerators(imgfolder, batch_size=8, val_fac=0.01)\n",
    "train_gen = dategen.training_generator()\n",
    "validation_gen = dategen.validation_generator()\n",
    "NUMBER_LABELS = dategen.number_labels\n",
    "#visualize_generator(dategen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model = InceptionV3(include_top=False, weights='imagenet', input_shape=(223,224,3))\n",
    "\n",
    "inputs_image = Input(shape=(224,224,1))\n",
    "x = Conv2D(3, kernel_size=(3,3), padding='same', activation='relu')(inputs_image)\n",
    "x = pretrained_model(x)\n",
    "x = Conv2D(1, (1,1), activation='relu')(x)\n",
    "outputs_pretrained = Flatten()(x)\n",
    "\n",
    "#x = Concatenate()([outputs_pretrained, output_stat])\n",
    "x = Dropout(0.2)(outputs_pretrained)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(3, activation='softmax', name=\"output\")(x)\n",
    "\n",
    "composite_model_w_pretrained_model = Model(inputs=[inputs_image], outputs=predictions)\n",
    "\n",
    "composite_model_w_pretrained_model.compile(optimizer='rmsprop', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "20/20 [==============================] - 29s 1s/step - loss: 1.6442 - acc: 0.4187\n",
      "Epoch 2/10\n",
      "20/20 [==============================] - 3s 127ms/step - loss: 1.0509 - acc: 0.4875\n",
      "Epoch 3/10\n",
      "20/20 [==============================] - 3s 134ms/step - loss: 1.1648 - acc: 0.4187\n",
      "Epoch 4/10\n",
      "20/20 [==============================] - 3s 129ms/step - loss: 1.0987 - acc: 0.3688\n",
      "Epoch 5/10\n",
      "20/20 [==============================] - 3s 129ms/step - loss: 1.1019 - acc: 0.4313\n",
      "Epoch 6/10\n",
      "20/20 [==============================] - 3s 127ms/step - loss: 1.1000 - acc: 0.4187\n",
      "Epoch 7/10\n",
      "20/20 [==============================] - 2s 123ms/step - loss: 1.1141 - acc: 0.3063\n",
      "Epoch 8/10\n",
      "20/20 [==============================] - 2s 123ms/step - loss: 1.1045 - acc: 0.4688\n",
      "Epoch 9/10\n",
      "20/20 [==============================] - 2s 121ms/step - loss: 1.0492 - acc: 0.4375\n",
      "Epoch 10/10\n",
      "20/20 [==============================] - 2s 123ms/step - loss: 1.0098 - acc: 0.5062\n"
     ]
    }
   ],
   "source": [
    "hist = fit_and_save_model(\"composite_model_w_pretrained_model\", composite_model_w_pretrained_model, train_gen,\n",
    "                  steps_per_epoch = 2*10, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
